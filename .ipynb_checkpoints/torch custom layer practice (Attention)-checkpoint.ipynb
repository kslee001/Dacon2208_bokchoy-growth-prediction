{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c289ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as f\n",
    "from torch.nn.utils import clip_grad_norm_ as clip_grad\n",
    "\n",
    "from tqdm.auto import tqdm as tq\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52526cba",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a7e16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(X, Y, batch_size, shuffle=True):\n",
    "    if shuffle:\n",
    "        permutation = np.random.permutation(X.shape[0])\n",
    "        X = X[permutation, :]\n",
    "        Y = Y[permutation, :]\n",
    "    num_steps = int(X.shape[0])//batch_size\n",
    "    step = 0\n",
    "    while step<num_steps:\n",
    "        X_batch = X[batch_size*step:batch_size*(step+1)]\n",
    "        Y_batch = Y[batch_size*step:batch_size*(step+1)]\n",
    "        step+=1\n",
    "        yield X_batch, Y_batch\n",
    "        \n",
    "        \n",
    "def valid(model, device, optimizer, criterion, batch_size, X_val, Y_val):\n",
    "    # mode change\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    # avoid unnecessary calculations\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in load_batch(X_val, Y_val, batch_size):\n",
    "            # forward\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)\n",
    "            yhat = model(X_batch)\n",
    "                \n",
    "            # loss\n",
    "            loss = criterion(yhat, Y_batch)\n",
    "            \n",
    "            # save loss values\n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "    return np.mean(val_loss)\n",
    "\n",
    "\n",
    "def train(model, device, criterion, optimizer, scheduler, clip, X_train, Y_train, X_val, Y_val, lr, n_epochs, batch_size, max_norm):\n",
    "    model.to(device)\n",
    "    \n",
    "    best_loss  = 999999999999\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in tq(range(1, n_epochs+1)):\n",
    "        train_loss = []\n",
    "        \n",
    "        # mode change\n",
    "        model.train()\n",
    "        for X_batch, Y_batch in load_batch(X_train, Y_train, batch_size):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            X_batch = X_batch.to(device)\n",
    "            Y_batch = Y_batch.to(device)            \n",
    "            yhat = model(X_batch)\n",
    "            \n",
    "            # loss\n",
    "            loss = criterion(yhat, Y_batch)\n",
    "            \n",
    "            # backward\n",
    "            loss.backward()\n",
    "            if clip :\n",
    "                clip_grad(model.parameters(), max_norm)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # save loss values\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "        val_loss = valid(model, device, optimizer, criterion, batch_size, X_val, Y_val)\n",
    "        print(f'Train Loss : [{np.mean(train_loss)/batch_size:.5f}] Valid Loss : [{val_loss:.5f}]')\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            if epoch > 20:\n",
    "                scheduler.step()\n",
    "            \n",
    "        if best_loss > val_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "            print(\" -- best model found -- \")\n",
    "    return best_model\n",
    "\n",
    "\n",
    "def preprocessing1(X_input, Y_input, X_container, Y_container): \n",
    "    global target_columns\n",
    "    y_maxlen = 0\n",
    "    \n",
    "    target_columns =[\n",
    "        1,2,3,4,5,6,\n",
    "9,\n",
    "21,24,27,\n",
    "29,30,\n",
    "35,36,37\n",
    "    ]\n",
    "    \n",
    "    for x,y in tq(zip(X_input, Y_input)):\n",
    "        curx = pd.read_csv(x)\n",
    "        curx.columns = [i for i in range(len(curx.columns))]\n",
    "        curx = curx[target_columns].fillna(0).values\n",
    "        x_len = len(curx)//1440\n",
    "        x_temp = []\n",
    "        for idx in range(x_len):\n",
    "            x_temp.append(curx[1440*idx : 1440*(idx+1)])\n",
    "        x_temp = torch.Tensor(x_temp)\n",
    "        X_container.append(x_temp)\n",
    "        y_temp = torch.Tensor(pd.read_csv(y)[\"rate\"].fillna(0).values)\n",
    "        y_temp = y_temp.reshape(y_temp.size()[0], 1)\n",
    "        Y_container.append(y_temp)\n",
    "    return \n",
    "\n",
    "\n",
    "def preprocessing2(X_input, Y_input, X_container, Y_container):    \n",
    "    y_maxlen = 0\n",
    "    for x,y in tq(zip(X_input, Y_input)):\n",
    "        curx = pd.read_csv(x).drop(columns = [\"시간\"]).fillna(0)\n",
    "        x_len = len(curx)//1440\n",
    "        x_temp = []\n",
    "        for idx in range(x_len):\n",
    "            cur_day = curx[1440*idx : 1440*(idx+1)]\n",
    "            x_day = []\n",
    "            for hour in range(24//2):\n",
    "                hour_data = cur_day.iloc[hour*60//2].T\n",
    "                x_day.append(hour_data)    \n",
    "            x_day = np.vstack(x_day)\n",
    "            x_temp.append(x_day)\n",
    "        \n",
    "        x_temp = torch.Tensor(x_temp)\n",
    "        X_container.append(x_temp)\n",
    "        y_temp = torch.Tensor(pd.read_csv(y)[\"rate\"].fillna(0).values)\n",
    "        y_temp = y_temp.reshape(y_temp.size()[0], 1)\n",
    "        Y_container.append(y_temp)\n",
    "    return;\n",
    "\n",
    "\n",
    "'''Loss function'''\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, yhat, ygt):\n",
    "        return torch.sqrt(self.mse(yhat, ygt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faccdfd",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6591c808",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_original(nn.Module):\n",
    "    def __init__(self, sublayer: nn.Module, dimension: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.sublayer = sublayer\n",
    "        self.norm = nn.LayerNorm(dimension)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, *tensors: torch.Tensor) -> torch.Tensor:\n",
    "        # Assume that the \"query\" tensor is given first, so we can compute the\n",
    "        # residual.  This matches the signature of 'MultiHeadAttention'.\n",
    "        return self.norm(tensors[0] + self.dropout(self.sublayer(*tensors)))\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, sublayer: nn.Module, dimension: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.sublayer = sublayer\n",
    "        self.norm = nn.LayerNorm(dimension)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, *tensors: torch.Tensor) -> torch.Tensor:\n",
    "        # Assume that the \"query\" tensor is given first, so we can compute the\n",
    "        # residual.  This matches the signature of 'MultiHeadAttention'.\n",
    "        return tensors[0] + self.dropout(self.norm(self.sublayer(*tensors)))\n",
    "    \n",
    "    \n",
    "def feed_forward(dim_input, dim_feedforward) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim_input, dim_feedforward),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(dim_feedforward, dim_input),\n",
    ")\n",
    "\n",
    "\n",
    "def position_encoding(seq_len, dim_model, \n",
    "                      device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")) -> torch.Tensor:\n",
    "    pos = torch.arange(seq_len, dtype=torch.float, device=device).reshape(1, -1, 1)\n",
    "    dim = torch.arange(dim_model, dtype=torch.float, device=device).reshape(1, 1, -1)\n",
    "    phase = pos / (1e4 ** (dim // dim_model))\n",
    "\n",
    "    return torch.where(dim.long() % 2 == 0, torch.sin(phase), torch.cos(phase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e5984",
   "metadata": {},
   "source": [
    "### Attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c84bbd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query:torch.Tensor, key:torch.Tensor, value:torch.Tensor)->torch.Tensor:  # value -> value\n",
    "    # temp : Q @ K.T   -> (N.T.D) @ (N,D,T)  (batch size만 그대로 두고, D,T 와 T, D를 )\n",
    "    # Q @ K.T -> (N, T, T)\n",
    "    QKT     = query.bmm(key.transpose(1, 2))  # bmm : batch matrix multiplication (X, O, O)-> O에 해당되는 dim에 대해서만 matmul 진행\n",
    "    root_dk = query.size(-1)**0.5            # squared root of D\n",
    "    softmax = f.softmax( QKT / root_dk, dim= -1 ) # softmax for \"T of Key\", not for \"T of Query\", so dim = -1 is right\n",
    "                                                  # dim = -2 로 맞추면 Key 에 대한 쿼리 결과(세로축)으로 1을 합산하는 꼴임\n",
    "    return softmax.bmm(value) # (N,T,T)@(N,T,D) -> (N, T, D)\n",
    "\n",
    "\n",
    "class AttentionHead(nn.Module): # X = (N, D)  / Wq, Wk, Wv : (D, Q) or (D, K) / 일반적으로 K, Q는 같은 dimension 사용\n",
    "    def __init__(self, input_dim:int, query_dim:int, key_dim:int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.q_linear = nn.Linear(input_dim, query_dim) # generate Q \n",
    "        self.k_linear = nn.Linear(input_dim, key_dim) # generate K\n",
    "        self.v_linaer = nn.Linear(input_dim, key_dim) # generate V\n",
    "\n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor) -> torch.Tensor:\n",
    "        # 인풋으로 들어온 query, key, value 텐서에 대해 linear forward를 진행하고\n",
    "        # 그 과정을 통해 만들어진 Q, K, V를 그대로 scaled_dot_product_attention 에 forward 시킴        \n",
    "        return scaled_dot_product_attention(\n",
    "            self.q_linear(query), # query @ q_linear : (Xq : N, D) @ (Wq : D, Q) -> (N, Q)\n",
    "            self.k_linear(key),   # key   @ k_linear : (Xk : N, D) @ (Wk : D, K) -> (N, K)\n",
    "            self.v_linaer(value)) # value @ v_linear : (Xv : N, D) @ (Wv : D, K) -> (N, K)\n",
    "    \n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads: int, input_dim: int, query_dim: int, key_dim: int):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(input_dim, query_dim, key_dim) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.linear = nn.Linear(num_heads * key_dim, input_dim)  \n",
    "        # num_heads 만큼 horizontally concat 되므로, \n",
    "        # multiheadAttention의 forward 결과 나오는 concated V의 dimension 은 numm_heads배 늘어난다. \n",
    "        # 즉, (N, T, K) * num_heads -> (N, T, num_heads * K)\n",
    "\n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(\n",
    "            torch.cat([ head(query, key, value) for head in self.heads], dim=-1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d55a65",
   "metadata": {},
   "source": [
    "### TransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a57b124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, num_heads, dim_model, dim_feedforward, dropout):\n",
    "        super().__init__()\n",
    "        dim_q = max(dim_model // num_heads, 1)\n",
    "        dim_k = dim_q\n",
    "        \n",
    "        self.attention = MultiHeadAttention(\n",
    "                num_heads = num_heads,\n",
    "                input_dim = dim_model,\n",
    "                query_dim = dim_q, \n",
    "                key_dim   = dim_k\n",
    "        )\n",
    "        \n",
    "        self.residual_AT = Residual(\n",
    "            sublayer  = self.attention,\n",
    "            dimension = dim_model,\n",
    "            dropout   = dropout\n",
    "        )\n",
    "            \n",
    "        self.feed_forward = feed_forward(\n",
    "            dim_input       = dim_model,\n",
    "            dim_feedforward = dim_feedforward\n",
    "        )\n",
    "            \n",
    "        self.residual_FF = Residual(\n",
    "            sublayer = self.feed_forward,\n",
    "            dimension = dim_model,\n",
    "            dropout   = dropout,\n",
    "        )\n",
    "\n",
    "    ''' source shape : (N, T, D)'''\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.residual_AT(x, x, x)\n",
    "        return self.residual_FF(x)\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_layers, \n",
    "                 num_heads, \n",
    "                 dim_model, \n",
    "                 dim_feedforward, \n",
    "                 dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerEncoderLayer(\n",
    "                    num_heads = num_heads, \n",
    "                    dim_model = dim_model, \n",
    "                    dim_feedforward = dim_feedforward, \n",
    "                    dropout = dropout\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # shape\n",
    "        if(x.ndim==2):\n",
    "            x = x.reshape(1, x.size(0), x.size(1))\n",
    "        N, T, D = x.shape\n",
    "        \n",
    "        # positional encoding\n",
    "        x += position_encoding(T, D)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a27a03",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edf1b172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01e99ccb05b44a59dc36815c1894286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1b5aa6f0a940609ccd1a8c7f985530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  시간\n",
      "1  :  내부온도관측치\n",
      "2  :  내부습도관측치\n",
      "3  :  CO2관측치\n",
      "4  :  EC관측치\n",
      "5  :  외부온도관측치\n",
      "6  :  외부습도관측치\n",
      "7  :  펌프상태\n",
      "8  :  펌프작동남은시간\n",
      "9  :  최근분무량\n",
      "10  :  일간누적분무량\n",
      "11  :  냉방상태\n",
      "12  :  냉방작동남은시간\n",
      "13  :  난방상태\n",
      "14  :  난방작동남은시간\n",
      "15  :  내부유동팬상태\n",
      "16  :  내부유동팬작동남은시간\n",
      "17  :  외부환기팬상태\n",
      "18  :  외부환기팬작동남은시간\n",
      "19  :  화이트 LED상태\n",
      "20  :  화이트 LED작동남은시간\n",
      "21  :  화이트 LED동작강도\n",
      "22  :  레드 LED상태\n",
      "23  :  레드 LED작동남은시간\n",
      "24  :  레드 LED동작강도\n",
      "25  :  블루 LED상태\n",
      "26  :  블루 LED작동남은시간\n",
      "27  :  블루 LED동작강도\n",
      "28  :  카메라상태\n",
      "29  :  냉방온도\n",
      "30  :  난방온도\n",
      "31  :  기준온도\n",
      "32  :  난방부하\n",
      "33  :  냉방부하\n",
      "34  :  총추정광량\n",
      "35  :  백색광추정광량\n",
      "36  :  적색광추정광량\n",
      "37  :  청색광추정광량\n"
     ]
    }
   ],
   "source": [
    "all_input_list  = sorted(glob.glob(\"train_input/*.csv\"))\n",
    "all_target_list = sorted(glob.glob(\"train_target/*.csv\"))\n",
    "# for training\n",
    "train_input_list = all_input_list[:50]\n",
    "train_target_list = all_target_list[:50]\n",
    "# for validation\n",
    "test_input_list = all_input_list[50:]\n",
    "test_target_list = all_target_list[50:]\n",
    "\n",
    "X_train = []; Y_train = []\n",
    "X_val  = []; Y_val  = []\n",
    "\n",
    "# call function\n",
    "preprocessing1(train_input_list, train_target_list, X_train, Y_train)\n",
    "preprocessing1(test_input_list, test_target_list, X_val, Y_val)\n",
    "\n",
    "# stack X, Y data\n",
    "X_train = torch.vstack(X_train)\n",
    "Y_train = torch.vstack(Y_train)\n",
    "X_val  = torch.vstack(X_val)\n",
    "Y_val  = torch.vstack(Y_val)\n",
    "\n",
    "cols = list(pd.read_csv(train_input_list[5]).columns)\n",
    "for idx, name in enumerate(cols):\n",
    "    print (idx, \" : \", name)\n",
    "    \n",
    "print(target_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee64fe",
   "metadata": {},
   "source": [
    "### Define model and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25497205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device : cuda\n",
      "lr             : 0.001\n",
      "n_epochs       : 40\n",
      "max_norm       : 10.0\n",
      "\n",
      "N (batch_size)  : 32\n",
      "T (time_step)   : 1440\n",
      "I (input_dim)   : 15\n",
      "H (hidden_dim)  : 4096\n",
      "O (output_dim)  : 1\n"
     ]
    }
   ],
   "source": [
    "class origin(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(origin, self).__init__()\n",
    "        \n",
    "        self.attention = TransformerEncoder(\n",
    "            num_layers = 6,\n",
    "            num_heads  = 6,\n",
    "            dim_model  = input_dim,\n",
    "            dim_feedforward = 128,\n",
    "            dropout = 0.1\n",
    "        )\n",
    "                \n",
    "        self.linear = nn.Linear(\n",
    "            in_features  = input_dim,\n",
    "            out_features = output_dim\n",
    "        )\n",
    "        \n",
    "        self.layers = [\n",
    "            self.attention,\n",
    "            self.linear\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.attention(x)\n",
    "        # final output\n",
    "        x = self.linear(x[:, -1, :])\n",
    "        return x\n",
    "        \n",
    "    \n",
    "'''parameters'''\n",
    "lr = 0.001\n",
    "n_epochs = 40\n",
    "max_norm = 10.0\n",
    "N = 32   # batch_size\n",
    "T = X_train.shape[1]\n",
    "I = X_train.shape[2]\n",
    "H = 4096\n",
    "O = Y_train.shape[1]  \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"current device : {device}\")\n",
    "print(f\"lr             : {lr}\")\n",
    "print(f\"n_epochs       : {n_epochs}\")\n",
    "print(f\"max_norm       : {max_norm}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"N (batch_size)  : {N}\")\n",
    "print(f\"T (time_step)   : {T}\")\n",
    "print(f\"I (input_dim)   : {I}\")\n",
    "print(f\"H (hidden_dim)  : {H}\")\n",
    "print(f\"O (output_dim)  : {O}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14214cd0",
   "metadata": {},
   "source": [
    "### Generate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7cffecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.lr_scheduler.ExponentialLR at 0x7fd832461c00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cad7c26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- optimizer -----\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    initial_lr: 0.001\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.1\n",
      ")\n",
      "\n",
      "----- scheduler -----\n",
      " <torch.optim.lr_scheduler.ExponentialLR object at 0x7fd832463a00>\n"
     ]
    }
   ],
   "source": [
    "''' model setting '''\n",
    "model = origin(I, H, O)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "    params=model.parameters(), \n",
    "    lr = lr,\n",
    "    eps = 1e-08,\n",
    "    weight_decay = 0.1\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "clip      = True\n",
    "\n",
    "# print(\"-----    model    -----\\n\", model)\n",
    "print(\"\\n----- optimizer -----\\n\", optimizer)\n",
    "print(\"\\n----- scheduler -----\\n\", scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b55bf6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ca9885ccd24a95b4fa2addbdbc2f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : [545643.24560] Valid Loss : [5322.35050]\n",
      " -- best model found -- \n",
      "Train Loss : [279493.10041] Valid Loss : [388.51203]\n",
      " -- best model found -- \n",
      "Train Loss : [104216.31277] Valid Loss : [182.78726]\n",
      " -- best model found -- \n",
      "Train Loss : [45333.17661] Valid Loss : [126.18271]\n",
      " -- best model found -- \n",
      "Train Loss : [19917.21432] Valid Loss : [73.30882]\n",
      " -- best model found -- \n",
      "Train Loss : [14938.01748] Valid Loss : [47.63030]\n",
      " -- best model found -- \n",
      "Train Loss : [7324.62994] Valid Loss : [31.13188]\n",
      " -- best model found -- \n",
      "Train Loss : [5424.68833] Valid Loss : [21.96693]\n",
      " -- best model found -- \n",
      "Train Loss : [2369.31633] Valid Loss : [10.05857]\n",
      " -- best model found -- \n",
      "Train Loss : [1025.69066] Valid Loss : [6.55020]\n",
      " -- best model found -- \n",
      "Train Loss : [369.28531] Valid Loss : [7.73243]\n",
      "Train Loss : [121.30756] Valid Loss : [2.97611]\n",
      " -- best model found -- \n",
      "Train Loss : [50.88093] Valid Loss : [3.63321]\n",
      "Train Loss : [2.83643] Valid Loss : [2.42716]\n",
      " -- best model found -- \n",
      "Train Loss : [9.30272] Valid Loss : [1.52905]\n",
      " -- best model found -- \n",
      "Train Loss : [1.30802] Valid Loss : [2.12477]\n",
      "Train Loss : [0.92213] Valid Loss : [0.91281]\n",
      " -- best model found -- \n",
      "Train Loss : [2.41999] Valid Loss : [1.10622]\n",
      "Train Loss : [5.40493] Valid Loss : [0.81803]\n",
      " -- best model found -- \n",
      "Train Loss : [8.22970] Valid Loss : [0.49441]\n",
      " -- best model found -- \n",
      "Train Loss : [0.29404] Valid Loss : [0.46918]\n",
      " -- best model found -- \n",
      "Train Loss : [0.80091] Valid Loss : [0.80458]\n",
      "Train Loss : [5.43359] Valid Loss : [0.41986]\n",
      " -- best model found -- \n",
      "Train Loss : [1.17052] Valid Loss : [0.59577]\n",
      "Train Loss : [4.91991] Valid Loss : [0.56040]\n",
      "Train Loss : [2.46912] Valid Loss : [0.35265]\n",
      " -- best model found -- \n",
      "Train Loss : [0.57803] Valid Loss : [0.35537]\n",
      "Train Loss : [3.26015] Valid Loss : [0.40220]\n",
      "Train Loss : [0.31626] Valid Loss : [0.49582]\n",
      "Train Loss : [3.17046] Valid Loss : [0.50492]\n",
      "Train Loss : [0.32293] Valid Loss : [0.31641]\n",
      " -- best model found -- \n",
      "Train Loss : [0.09471] Valid Loss : [0.32107]\n",
      "Train Loss : [0.12177] Valid Loss : [0.29676]\n",
      " -- best model found -- \n",
      "Train Loss : [0.59726] Valid Loss : [0.29105]\n",
      " -- best model found -- \n",
      "Train Loss : [1.12398] Valid Loss : [0.44339]\n",
      "Train Loss : [0.24617] Valid Loss : [0.33085]\n",
      "Train Loss : [0.11323] Valid Loss : [0.31821]\n",
      "Train Loss : [0.15792] Valid Loss : [0.28131]\n",
      " -- best model found -- \n",
      "Train Loss : [0.25046] Valid Loss : [0.30253]\n",
      "Train Loss : [0.25075] Valid Loss : [0.28985]\n"
     ]
    }
   ],
   "source": [
    "best_model = train(\n",
    "    model, \n",
    "    device, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    clip, \n",
    "    X_train, \n",
    "    Y_train, \n",
    "    X_val, \n",
    "    Y_val, \n",
    "    lr, \n",
    "    n_epochs, \n",
    "    N,\n",
    "    max_norm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6240ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c42adad",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2ce5df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02452521026134491\n",
      "0.2194100022315979\n"
     ]
    }
   ],
   "source": [
    "idx = 50\n",
    "tempx = X_train[idx].to(device)\n",
    "print(best_model.forward(tempx).item())\n",
    "\n",
    "tempy = Y_train[idx].to(device)\n",
    "print(tempy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0072e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), \"best_model_0906\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d9212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tch",
   "language": "python",
   "name": "tch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
